<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tomas Knapen">

<title>fMRI by caveat</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="paper_files/libs/clipboard/clipboard.min.js"></script>
<script src="paper_files/libs/quarto-html/quarto.js"></script>
<script src="paper_files/libs/quarto-html/popper.min.js"></script>
<script src="paper_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="paper_files/libs/quarto-html/anchor.min.js"></script>
<link href="paper_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="paper_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="paper_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="paper_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="paper_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script src="paper_files/libs/quarto-contrib/videojs/video.min.js"></script>
<link href="paper_files/libs/quarto-contrib/videojs/video-js.css" rel="stylesheet">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#abstract" id="toc-abstract" class="nav-link active" data-scroll-target="#abstract">Abstract</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#goal-and-scope" id="toc-goal-and-scope" class="nav-link" data-scroll-target="#goal-and-scope">Goal and Scope</a></li>
  <li><a href="#caveats-galore" id="toc-caveats-galore" class="nav-link" data-scroll-target="#caveats-galore">Caveats Galore</a></li>
  </ul></li>
  <li><a href="#caveats" id="toc-caveats" class="nav-link" data-scroll-target="#caveats">Caveats</a>
  <ul class="collapse">
  <li><a href="#imaging" id="toc-imaging" class="nav-link" data-scroll-target="#imaging">Imaging</a>
  <ul class="collapse">
  <li><a href="#c1" id="toc-c1" class="nav-link" data-scroll-target="#c1">Caveat I: MR Images are very different from photographs</a></li>
  <li><a href="#c2" id="toc-c2" class="nav-link" data-scroll-target="#c2">Caveat II: The scanner can image many things. BOLD is just one of those things.</a></li>
  <li><a href="#c3" id="toc-c3" class="nav-link" data-scroll-target="#c3">Caveat III: Things in an MR image may not be where they appear to be.</a></li>
  </ul></li>
  <li><a href="#interpreting-the-bold-response" id="toc-interpreting-the-bold-response" class="nav-link" data-scroll-target="#interpreting-the-bold-response">Interpreting the BOLD Response</a>
  <ul class="collapse">
  <li><a href="#c4" id="toc-c4" class="nav-link" data-scroll-target="#c4">Caveat IV: Blood, not neurons.</a></li>
  <li><a href="#c5" id="toc-c5" class="nav-link" data-scroll-target="#c5">Caveat V: Dissociations between BOLD and neuronal firing.</a></li>
  <li><a href="#c6" id="toc-c6" class="nav-link" data-scroll-target="#c6">Caveat VI: Yellow-red blobs are statistics, not ‘activation’.</a></li>
  <li><a href="#c7" id="toc-c7" class="nav-link" data-scroll-target="#c7">Caveat VII: the BOLD response is not the only functional contrast mechanism that we can use to measure brain activations.</a></li>
  <li><a href="#c8" id="toc-c8" class="nav-link" data-scroll-target="#c8">Caveat VIII: Gradient-recalled echo imaging is very sensitive but less selective than other acquisitions.</a></li>
  <li><a href="#c9" id="toc-c9" class="nav-link" data-scroll-target="#c9">Caveat IX: The shape of the BOLD response differs a lot across voxels, individuals, and age.</a></li>
  </ul></li>
  <li><a href="#analysis-statistical-inference" id="toc-analysis-statistical-inference" class="nav-link" data-scroll-target="#analysis-statistical-inference">Analysis &amp; Statistical Inference</a>
  <ul class="collapse">
  <li><a href="#c10" id="toc-c10" class="nav-link" data-scroll-target="#c10">Caveat X: our use of the GLM depends on an LTI assumption.</a></li>
  <li><a href="#c11" id="toc-c11" class="nav-link" data-scroll-target="#c11">Caveat XI: GLM statistics depend on specific assumptions.</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">Discussion</a>
  <ul class="collapse">
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">fMRI by caveat</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Tomas Knapen </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="abstract" class="level1">
<h1>Abstract</h1>
<p><em>Imaging of human brain activations has revolutionized cognitve neuroscience, and fundamentally changed how the general public thinks about the mind. In recent years, the burgeoning growth of the field of functional magnetic resonance imaging has plateaued. The development of the field has not been gradual, but rather has been interpunctuated by sudden shifts in insight. These shifts have driven thinking and practices in the field forward. In many cases, these sudden shifts have been prompted by a realization that some caveat applies to the interpretation of results produced by current practices. I have found that when teaching fMRI these caveats provide a productive conceptual framework, that helps students understand the history of the field, but also its present limitations and promises. Therefore, this paper is structured as a list of caveats, ordered broadly according to both topic and historical order.</em></p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that this document doesn’t aim to provide a full introduction into neuroimaging or its analysis. If you’re interested in that, I recommend consulting the excellent <a href="https://textbook.nipraxis.org/intro.html">nipraxis</a> website, or the <a href="https://sites.google.com/site/fmridataanalysis/home">fmri handbook</a> by Russ Poldrack et al.</p>
</div>
</div>
</section>
<section id="introduction" class="level1">
<h1>Introduction</h1>
<section id="goal-and-scope" class="level2">
<h2 class="anchored" data-anchor-id="goal-and-scope">Goal and Scope</h2>
<p>This document is intended as a corollary to a first-year graduate level introduction to neuroimaging in a cognitive neuroscience curriculum. Some caveats may also be applicable to other imaging modalities used in cognitive science, and perhaps other caveats apply in different fields also. Nonetheless, the strict focus here is on the use of fMRI to answer questions about the underpinnings of the mind in the brain.</p>
</section>
<section id="caveats-galore" class="level2">
<h2 class="anchored" data-anchor-id="caveats-galore">Caveats Galore</h2>
<p>What is a caveat? One could say that it’s short for “caveat emptor”, a Latin phrase which means: “Buyer beware”. It refers to the principle that “the buyer alone is responsible for checking the quality and suitability of goods before a purchase is made”. Now, in everyday life we have legal consumer protection when we buy something. But in science, there is no such governmental oversight: we are the buyers of nature’s knowledge, and no guarantee is given.</p>
<p>So, a caveat is <strong>“a warning or proviso of specific stipulations, conditions, or limitations”</strong>. As a scientific field, we’ve had to learn these conditions and limitations the hard way, by making mistakes. We can learn a lot about a field by going through the mistakes that the field has made - to quote Niels Bohr: <em>“An expert is a person who has made all the mistakes that can be made in a very narrow field”</em>. Thus, learning a field through all its past mistakes is a very efficient way of becoming an expert. It’s important to realize that when we explicitly identify these mistakes we don’t do this to make fun of past scientists’ stupidity. Rather, by focusing on mistakes and the caveats they’ve become we learn not just the field’s subject matter, but also how it has tended to evolve as a collective human enterprise. This may allows us to learn strategies that help us avoid future mistakes.</p>
</section>
</section>
<section id="caveats" class="level1 page-columns page-full">
<h1>Caveats</h1>
<section id="imaging" class="level2">
<h2 class="anchored" data-anchor-id="imaging">Imaging</h2>
<section id="c1" class="level3">
<h3 class="anchored" data-anchor-id="c1">Caveat I: MR Images are very different from photographs</h3>
<p>The universe doesn’t care about us. It certainly hasn’t structured itself such as to make sure that we can look inside living human brains using giant magnets. MRI, like most if not all measurements we do in science, relies on serendipitously discovered principles and often very contrived methods. We’ll take what we can get in order to learn about the things we’re interested in. Just as a left-field example, <a href="https://www.economist.com/science-and-technology/2017/09/30/counting-raindrops-using-mobile-phone-towers">we can measure precipitation using cell phone towers</a> - the cell phone towers definitely weren’t put there to measure precipitation. Similary for MRI, it’s important to realize that our ability to image the human brain without opening it up rests on our understanding of electromagnetic physical principles and our electrical engineering prowess. This ability is the result of decades of development by some of the smartest people in the world, and the MRI machine is a marvel of our understanding and manipulation of super-low-level physical properties of matter. So, it’s important to realize that the brain images from an MR scanner aren’t like the pictures taken by your phone, where photons fall on detectors to create an image similar to how our own retinae detect photons. Rather, MRI images are the result of an intricate process of construction through an thorough manipulation of low-level physical things.</p>
</section>
<section id="c2" class="level3">
<h3 class="anchored" data-anchor-id="c2">Caveat II: The scanner can image many things. BOLD is just one of those things.</h3>
<p>Depending on how we use the scanner, or the ‘sequence’ that it runs, we get out different kinds of data. These can be images, but can also be NMR spectra that relate to the chemical composition of the thing in the magnet. If the outcome is an image, it can take many different forms. Depending on specific settings such as the repetition time, the echo time, and how we ‘read out’ the image, images can be sensitive to iron content, tissue perfusion, blood flow direction, nerve fiber bundle orientation, and many more things. In fMRI, we usually use a specific contrast called a T2* contrast, which is sensitive to – among other things – the level of oxygenation of the haemoglobin in the blood. But a T2* contrast image, like the T1-weighted image we usually associate with anatomical brain scans, is just an image of some complex set of properties of the brain’s tissues. This means we can also make anatomical images using the same contrast:</p>
<div class="quarto-video"><video id="video_shortcode_videojs_video1" width="400" height="400" class="video-js vjs-default-skin " controls="" preload="auto" data-setup="{}" title="“a"><source src="figs/T2star_axial.mov"></video></div>
</section>
<section id="c3" class="level3">
<h3 class="anchored" data-anchor-id="c3">Caveat III: Things in an MR image may not be where they appear to be.</h3>
<p>The scanner constructs the image by playing around with magnetic moments and recording radio frequency signals; <em>construction</em> being the crucial term here, as outlined in Caveat I. Again depending on how the scanner constructs the image, it may be a faithful representation of the spatial relations inside the head, or the image may be (severely) warped or distorted. These distortions in the image are due to the fact that the homogeneity of the main magnetic field (B<span class="math inline">\(_0\)</span>) is disturbed by strong changes in magnetic properties, such as the change from tissue to air. If our sequence is sensitive to these disturbances, our images will be distorted.</p>
</section>
</section>
<section id="interpreting-the-bold-response" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="interpreting-the-bold-response">Interpreting the BOLD Response</h2>
<p><strong>The images of ‘activation’ we see in the press aren’t images of neurons firing</strong></p>
<p>We often see blobs of ‘activation’ being reported, and the implicit idea is that this represents neurons firing in a living human brain. But the measurement that fMRI usually involves is much more indirect. This means that any fMRI article that does human BOLD imaging and then concludes things about neural firing is crossing a line it shouldn’t cross. There are several sub-caveats here:</p>
<section id="c4" class="level3">
<h3 class="anchored" data-anchor-id="c4">Caveat IV: Blood, not neurons.</h3>
<p>First off, we are looking at a blood response. That is, our Blood-Oxygenation Level Dependent (BOLD) measurements reflect the ratio of non-paramagnetic oxygenated haemoglobin to paramagnetic deoxygenated haemoglobin. This ratio is altered by neural activity, surely, but it does so through a complex cascade of biological responses in several types of tissue – not just the neurons, but also the astrocytes and cells in the vessel walls. Some important parts of this cascade are changes in cerebral blood volume (CBV), cerebral blood flow (CBF), and the rate of cerebral blood oxygen consumption (CMRO<span class="math inline">\(_2\)</span>). Even though perhaps we want to infer things about neural firing, we’ll always be looking at this through a blood-lens.</p>
</section>
<section id="c5" class="level3">
<h3 class="anchored" data-anchor-id="c5">Caveat V: Dissociations between BOLD and neuronal firing.</h3>
<p>We want to be able to measure a BOLD response, and use it to infer something about neural activation, but this link is indirect. One repercussion of this indirectness is shown by examples from animal studies that conduct simultaneous BOLD and neural measurements. Several of these studies show that we can have strong BOLD responses even without neural firing. These non-neural BOLD responses are likely driven by task-related expectations that modulate the animal’s arousal<span class="citation" data-cites="10.1038/nature07664"><sup><a href="#ref-10.1038/nature07664" role="doc-biblioref">1</a></sup></span>. The link between neural firing and BOLD is also influenced by dopaminergic stimulation<span class="citation" data-cites="10.1016/j.cub.2014.10.006"><sup><a href="#ref-10.1016/j.cub.2014.10.006" role="doc-biblioref">2</a></sup></span>. This means that when we see a BOLD response, this may not be the clear evidence of neural activations that we would want it to be.</p>
</section>
<section id="c6" class="level3">
<h3 class="anchored" data-anchor-id="c6">Caveat VI: Yellow-red blobs are statistics, not ‘activation’.</h3>
<p>A more trivial point, perhaps, but important nonetheless. The nice blobs we see in the newspaper indicating the ‘love’, ‘jealousy’, or ‘political affiliation’ region in the brain aren’t images of <em>activation</em>. They are a value, often a T-statistic, that relates to the certainty we have when we conclude some difference between conditions exist. For example, that ‘love’ blob might reflect our confidence when we conclude that the BOLD response in this region is different when looking at photos of loved ones vs photos of people we don’t know. We need to keep in mind that how to regard this result requires knowing more about 1. the experiment, and 2. the analysis that delivered this result. Remember, there are <a href="https://en.wikipedia.org/wiki/Lies,_damned_lies,_and_statistics">lies, damned lies, and statistics</a>.</p>
</section>
<section id="c7" class="level3">
<h3 class="anchored" data-anchor-id="c7">Caveat VII: the BOLD response is not the only functional contrast mechanism that we can use to measure brain activations.</h3>
<p>The endogenous contrast agent that haemoglobin is, which makes BOLD imaging possible, is not the only possible contrast. There are actually quite a lot of other MR contrast mechanisms that also correlate with neuronal activation. These focus on CBV and/or CBF to provide time-varying signal fluctuations that we can relate to brain function. Depending on our scientific question, we may (have to) adopt these other contrast mechanisms. Examples of these used for very selective functional imaging are <a href="https://doi.org/10.1016/j.neuroimage.2016.11.039">vascular-space occupancy (VASO)</a>, or <a href="https://doi.org/10.1002/hbm.26227">arterial blood contrast (ABC)</a>.</p>
</section>
<section id="c8" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="c8">Caveat VIII: Gradient-recalled echo imaging is very sensitive but less selective than other acquisitions.</h3>
<p>The “standard” BOLD imaging technique reverses spins after excitation using a change in the magnetic field gradient. We then capture RF signals after they re-align to form an ‘echo’. Hence the name gradient-recalled echo (GRE) or gradient echo (GE). An older alternative technique, devised by Erwin Hahn in 1949, is called spin echo (SE). In this scheme, a 180<span class="math inline">\(\degree\)</span> RF pulse is used to reflect the magnetic spins, so that the return to form an RF ‘echo’. The time at which the echo happens is double that at which the 180<span class="math inline">\(\degree\)</span> RF pulse was applied. SE is used a lot in anatomical imaging in the form of turbo-spin-echo sequences, in which continuous 180<span class="math inline">\(\degree\)</span> RF pulse reflections are used to speed up acquisition. For functional MRI, SE is less sensitive but more selective than GRE. We can use it to focus more on effect originating from smaller vessels, whereas GRE is often biased by signals originating from larger vessels. <a href="https://mriquestions.com/gre-vs-se.html">mri-questions on GRE vs SE</a></p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://mriquestions.com/uploads/3/4/5/7/34572113/_7041819_orig.gif" class="img-fluid figure-img" alt="Spin-Echo animation"></p>
<p></p><figcaption class="figure-caption">Spin-Echo animation from Wikipedia</figcaption><p></p>
</figure>
</div>
</div></div></section>
<section id="c9" class="level3">
<h3 class="anchored" data-anchor-id="c9">Caveat IX: The shape of the BOLD response differs a lot across voxels, individuals, and age.</h3>
<p>Our standard GLM analysis assumes that BOLD responses follow a stereotypical haemodynamic response function (HRF) shape. This is not true. There are large difference in BOLD response (HRF) shape from measurement to measurement. Here are some important factors to keep in mind.</p>
<ul>
<li>voxels containing more and/or larger veins will have a stronger BOLD response with a slower rise time and a later peak<span class="citation" data-cites="10.1038/jcbfm.2011.57"><sup><a href="#ref-10.1038/jcbfm.2011.57" role="doc-biblioref">3</a></sup></span>.</li>
<li>for ultra-high resolution fMRI, this means that the voxels closer to the pial surface have a 2-fold stronger signal than voxels closer to the white-matter gray-matter boundary<span class="citation" data-cites="10.1038/s41592-020-0941-6"><sup><a href="#ref-10.1038/s41592-020-0941-6" role="doc-biblioref">4</a></sup></span>.</li>
<li>the original HRF shapes were derived from 1.5-Tesla measurements<span class="citation" data-cites="10.1523/jneurosci.16-13-04207.1996"><sup><a href="#ref-10.1523/jneurosci.16-13-04207.1996" role="doc-biblioref">5</a></sup></span>. Present-day 7-Tesla measurements show a faster response because they inherently weigh signals from smaller veins more strongly, and these are faster to respond whenever neurons activate.</li>
<li>we only have good estimates of the HRF shape in primary brain regions, such as primary motor cortex or primary visual cortex. This is because only when we can provide an ‘impulse’ (a very strong and very brief stimulus) can we estimate the shape of the impulse-response to this input event. For many other brain regions we simply don’t know how to activate neurons briefly and strongly, but for motor or visual cortex that can be done by finger-tapping or presenting a flickering checkerboard stimulus, respectively.</li>
</ul>
</section>
</section>
<section id="analysis-statistical-inference" class="level2">
<h2 class="anchored" data-anchor-id="analysis-statistical-inference">Analysis &amp; Statistical Inference</h2>
<section id="c10" class="level3">
<h3 class="anchored" data-anchor-id="c10">Caveat X: our use of the GLM depends on an LTI assumption.</h3>
<p>The use of the GLM depends on the assumption that the relation between the BOLD response and the thing of interest (neural responses) is a linear time-invariant (LTI) system. This means that doubling the strength of a neural signal will show a double amplitude response in the BOLD response. It also means that the response to a two-second event is equal to the sum of two one-second event responses, the second having been shifted by 1 second. Using these assumptions we can now use convolution with the impulse-response of the system (the HRF) to predict BOLD responses driven by specific events. Also, this means that we can gauge the strength of neural responses by looking at the <span class="math inline">\(\beta\)</span> weights that roll out of a GLM. It’s important to realize that this is an <em>assumption</em> that we cannot fully verify. It’s clear that as a first pass it holds, though, but as opposed to simple electrical wirings, the complicated biological machinery driving the BOLD response is likely to show nonlinearities that break the LTI assumption. Just check out the examples above in Caveat<span class="citation" data-cites="c5"><sup><a href="#ref-c5" role="doc-biblioref"><strong>c5?</strong></a></sup></span> to convince yourself that there are limits to the LTI assumption<span class="citation" data-cites="10.1038/nature07664"><sup><a href="#ref-10.1038/nature07664" role="doc-biblioref">1</a></sup></span>.</p>
</section>
<section id="c11" class="level3">
<h3 class="anchored" data-anchor-id="c11">Caveat XI: GLM statistics depend on specific assumptions.</h3>
<p>The statistics we do on top of our GLMs assume independent, identically distributed samples - an assumption that is very common in more statistical applications. However, the noise that ends up as residuals actually has strong temporal autocorrelation. This means that the covariance structure of the noise doesn’t follow an identity matrix, and that we should estimate this structure and use it to correct our statistics. If we do not take into account this correlational structure in our noise, we will overestimate the degrees of freedom that go into our T-statistic calculations, greatly inflating them and causing a lot of false positives. Similarly, cluster-based statistical procedures often use assumptions regarding the spatial autocorrelation of noise. If we assume such structure to be more narrow than it actually is, we run into problems<span class="citation" data-cites="10.1073/pnas.1602413113"><sup><a href="#ref-10.1073/pnas.1602413113" role="doc-biblioref">6</a></sup></span>. These problems, as in<span class="citation" data-cites="c10"><sup><a href="#ref-c10" role="doc-biblioref"><strong>c10?</strong></a></sup></span>, are that we will be too lenient and produce false-positive results.</p>
</section>
</section>
</section>
<section id="discussion" class="level1">
<h1>Discussion</h1>
<section id="references" class="level3">
<h3 class="anchored" data-anchor-id="references">References</h3>
<div id="refs" class="references csl-bib-body" data-line-spacing="2" role="doc-bibliography">
<div id="ref-10.1038/nature07664" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Sirotin, Y. B. &amp; Das, A. <a href="https://doi.org/10.1038/nature07664"><span class="nocase">Anticipatory haemodynamic signals in sensory cortex not predicted by local neuronal activity</span></a>. <em>Nature</em> <strong>457</strong>, 475 479 (2009).</div>
</div>
<div id="ref-10.1016/j.cub.2014.10.006" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Zaldivar, D., Rauch, A., Whittingstall, K., Logothetis, N. K. &amp; Goense, J. <a href="https://doi.org/10.1016/j.cub.2014.10.006"><span class="nocase">Dopamine-Induced Dissociation of BOLD and Neural Activity in Macaque Visual Cortex</span></a>. <em>Current Biology</em> <strong>24</strong>, 2805 2811 (2014).</div>
</div>
<div id="ref-10.1038/jcbfm.2011.57" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Siero, J. C. W., Petridou, N., Hoogduin, H., Luijten, P. R. &amp; Ramsey, N. F. <a href="https://doi.org/10.1038/jcbfm.2011.57"><span class="nocase">Cortical depth-dependent temporal dynamics of the BOLD response in the human brain.</span></a> <em>Journal of cerebral blood flow and metabolism : official journal of the International Society of Cerebral Blood Flow and Metabolism</em> <strong>31</strong>, 1999 2008 (2011-10).</div>
</div>
<div id="ref-10.1038/s41592-020-0941-6" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Kay, K., Jamison, K. W., Zhang, R.-Y. &amp; Uğurbil, K. <a href="https://doi.org/10.1038/s41592-020-0941-6"><span class="nocase">A temporal decomposition method for identifying venous effects in task-based fMRI</span></a>. <em>Nature Methods</em> <strong>17</strong>, 1033–1039 (2020).</div>
</div>
<div id="ref-10.1523/jneurosci.16-13-04207.1996" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Boynton, G. M., Engel, S. A., Glover, G. H. &amp; Heeger, D. J. <a href="https://doi.org/10.1523/jneurosci.16-13-04207.1996"><span class="nocase">Linear Systems Analysis of Functional Magnetic Resonance Imaging in Human V1</span></a>. <em>Journal of Neuroscience</em> <strong>16</strong>, 4207–4221 (1996).</div>
</div>
<div id="ref-10.1073/pnas.1602413113" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Eklund, A., Nichols, T. E. &amp; Knutsson, H. <a href="https://doi.org/10.1073/pnas.1602413113"><span class="nocase">Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates</span></a>. <em>Proceedings of the National Academy of Sciences</em> <strong>113</strong>, 7900–7905 (2016).</div>
</div>
</div>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<script>videojs(video_shortcode_videojs_video1);</script>



</body></html>